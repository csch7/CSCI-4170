{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHistwKf2k+mMfQ1dkGOxY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/csch7/CSCI-4170/blob/main/Homework-06/Transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://paperswithcode.com/dataset/xl-sum"
      ],
      "metadata": {
        "id": "TiQ62q_91tjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTSngS1HutdR",
        "outputId": "d828960b-5de9-4175-9f64-cf1420ef6baa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.14)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.29.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZcmAH9WdoY2",
        "outputId": "df59588f-caff-4a9b-b2d6-5814738355b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration\n",
        "from datasets import load_dataset\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "dat = load_dataset('csebuetnlp/xlsum', 'english')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = dat['train'].to_pandas()\n",
        "test = pd.concat([dat['test'].to_pandas(), dat['validation'].to_pandas()])\n",
        "\n",
        "print(train.shape, test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27KErqKtwZLS",
        "outputId": "632065cf-cb30-4db4-bffb-a448a938731f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(306522, 5) (23070, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.iloc[:230700]\n",
        "print(train.shape, test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1HpSJqb2nMz",
        "outputId": "2576c98d-27ce-416c-f265-97da4c29fc67"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(230700, 5) (23070, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpQ4XuSm3Moi",
        "outputId": "2707f154-05cf-49cc-d0e6-2bb196dac006"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                       id  \\\n",
            "0                       uk-wales-56321577   \n",
            "1  uk-scotland-highlands-islands-11069985   \n",
            "2               uk-england-leeds-45776523   \n",
            "3                world-us-canada-51010441   \n",
            "4       uk-scotland-glasgow-west-52274685   \n",
            "\n",
            "                                                 url  \\\n",
            "0         https://www.bbc.com/news/uk-wales-56321577   \n",
            "1  https://www.bbc.com/news/uk-scotland-highlands...   \n",
            "2  https://www.bbc.com/news/uk-england-leeds-4577...   \n",
            "3  https://www.bbc.com/news/world-us-canada-51010441   \n",
            "4  https://www.bbc.com/news/uk-scotland-glasgow-w...   \n",
            "\n",
            "                                               title  \\\n",
            "0  Weather alert issued for gale force winds in W...   \n",
            "1   Huge tidal turbine installed at Orkney test site   \n",
            "2  Leeds stabbing: Man attacked outside betting shop   \n",
            "3  Could killing of Iranian general help Trump ge...   \n",
            "4  Coronavirus: 'I've moved out to protect my fam...   \n",
            "\n",
            "                                             summary  \\\n",
            "0  Winds could reach gale force in Wales with sto...   \n",
            "1  The massive tidal turbine AK1000 has been inst...   \n",
            "2  A man has been stabbed in broad daylight outsi...   \n",
            "3  It was inevitable that the fallout from the US...   \n",
            "4  Week four of social distancing is starting to ...   \n",
            "\n",
            "                                                text  \n",
            "0  The Met Office has issued a yellow weather war...  \n",
            "1  Atlantis Resources unveiled the marine energy ...  \n",
            "2  Police were called to the scene outside the Co...  \n",
            "3  Anthony ZurcherNorth America reporter@awzurche...  \n",
            "4  By Debbie JacksonBBC Scotland But while most o...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.drop(columns=['id', 'url', 'title'])\n",
        "test = test.drop(columns=['id', 'url', 'title'])\n"
      ],
      "metadata": {
        "id": "vqBrlWLp3V_w"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.head(), test.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcQXkLgL30mo",
        "outputId": "c2c5a684-7fdb-4a98-c769-05b45039ff6c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             summary  \\\n",
            "0  Winds could reach gale force in Wales with sto...   \n",
            "1  The massive tidal turbine AK1000 has been inst...   \n",
            "2  A man has been stabbed in broad daylight outsi...   \n",
            "3  It was inevitable that the fallout from the US...   \n",
            "4  Week four of social distancing is starting to ...   \n",
            "\n",
            "                                                text  \n",
            "0  The Met Office has issued a yellow weather war...  \n",
            "1  Atlantis Resources unveiled the marine energy ...  \n",
            "2  Police were called to the scene outside the Co...  \n",
            "3  Anthony ZurcherNorth America reporter@awzurche...  \n",
            "4  By Debbie JacksonBBC Scotland But while most o...                                                summary  \\\n",
            "0  Donald Trump campaigned on becoming a presiden...   \n",
            "1  The Welsh Government \"would probably\" take the...   \n",
            "2  A university has mistakenly emailed hundreds o...   \n",
            "3  Some progress has been made in encouraging gir...   \n",
            "4  The president of business organisation, the CB...   \n",
            "\n",
            "                                                text  \n",
            "0  By Kate DaileyBBC News Earlier this week, Trum...  \n",
            "1  But Eluned Morgan conceded that it would be \"d...  \n",
            "2  By Jon Welch and Paul MoseleyBBC News Details ...  \n",
            "3  By Helen BriggsBBC News In 2016, 1.9% of girls...  \n",
            "4  John Allan stressed this was his personal view...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n",
        "\n",
        "model = BartForConditionalGeneration.from_pretrained('facebook/bart-base')"
      ],
      "metadata": {
        "id": "Xx4X-Ov-wZc-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "encoded_articles = []\n",
        "encoded_summaries = []\n",
        "\n",
        "for i in tqdm(range(10000), total=10000):\n",
        "  encoded_articles.append(torch.tensor(tokenizer.encode(train.text.iloc[i][:500], max_length=5)))\n",
        "  encoded_summaries.append(torch.tensor(tokenizer.encode(train.summary.iloc[i], max_length=5)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_N9rD7W4JF7",
        "outputId": "50235193-17b5-43dc-ca29-3455bbd83de2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [00:24<00:00, 401.11it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def train_Bart(data, labels, model, batch_size = 32, epochs = 10, lr = 0.001):\n",
        "\n",
        "  model.train()\n",
        "  optimizer = optim.AdamW(model.parameters(), lr)\n",
        "\n",
        "  data = [data] + [labels]\n",
        "  train_loader = DataLoader(data, batch_size, shuffle=True)\n",
        "\n",
        "  for e in range(epochs):\n",
        "\n",
        "    train_loader = iter(train_loader)\n",
        "    i = 0\n",
        "    while i < len(train_loader):\n",
        "      optimizer.zero_grad()\n",
        "      batch = next(train_loader)\n",
        "      print(len(batch), batch[1].shape)\n",
        "      model_output = model(batch[0], labels=batch[1])\n",
        "      loss = model_output.loss\n",
        "      print(loss.item())\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      i+=1\n",
        "\n",
        "\n",
        "train_Bart(encoded_articles, encoded_summaries, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "6oPdmCskS0CY",
        "outputId": "234fe6a0-4f71-44e5-cf76-ea2064706f08"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000 torch.Size([2, 5])\n",
            "12.803457260131836\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-f7cc677d1f3d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mtrain_Bart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_articles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded_summaries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-27-f7cc677d1f3d>\u001b[0m in \u001b[0;36mtrain_Bart\u001b[0;34m(data, labels, model, batch_size, epochs, lr)\u001b[0m\n\u001b[1;32m     21\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m       \u001b[0mi\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}