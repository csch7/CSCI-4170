## Real-world Markov Decision Process

One problem that could be formulated as an MDP is simply trading a stock -- buying or selling. One extremely simplified formulation of this problem is as follows:
- _State Space:_ $S=\lbrace P, \dot{P}, P500, \dot{P500}\rbrace$, where $P$ is the price of the stock in question, $\dot{P}$ is the instantaneous derivative of the stock price, and $P500$ and $\dot{P500}$ are the same metrics of the S\&P 500. This is of course a simplified version -- if this MDP were needed to make actual policy decisions, the state space would include many more variables.
- _Action Space:_ $A = \lbrace -M, -M+1, ..., M-1, M\rbrace$, where $-M$ corresponds to selling $M$ shares of the stock, and $M$ corresponds to buying $M$ shares of the stock. $M$ is a sort of hyperparameter denoting how much of a change you can possibly make at one step.
- _Transition Model:_ This would be purely based on the actual market value of the stock market at each step. If we had extensive historical data, this could be modeled as the probability of the price going down, staying the same, or going up, given the closest historical states to the current state.
- _Rewards:_ $R = \alpha(\Delta P)a$, where $\alpha$ is some hyperparameter, $\Delta P$ is the change in stock price after taking an action, and $a$ is the action taken. With this reward system, actions that either sell before the stock price goes down or buy before the stock price goes up are rewarded, while actions that sell before the stock price goes up or buy before the stock price goes down are penalized. Therefore, this reward model will maximize trading profit once optimized.


## RL in Healthcare
  
One potential application for RL in healthcare is dosing diabetic patients with insulin. With reinforcement learning, effective dosing strategies can be done with careful monitoring of the patient's blood sugar level. One paper exploring this usage, "Optimized glycemic control of type 2 diabetes with reinforcement learning: a proof-of-concept trial" ( [https://www.nature.com/articles/s41591-023-02552-9](source) ), constructs a policy using RL and then evaluates the proposed policy with consultations to actual physicians. In healthcare, patient safety is the primary concern, so the evaluation of AI techniques must be rigorous and all-encompassing before being deployed into real-world situations. Therefore, this paper evaluated the role of RL carefully in three stages -- a retrospective study, a prospective study with direct physician supervision, and a proof-of-concept trial with only 16 eligible patients. The actual policy was constructed using a model-based RL in conjunction with supervised learning, and a patient model which outputs a status prediction and reward is used as input to the policy. The model then predicts the patient's future glucose level, and, based on this, determines when to give insulin dosages, and how powerful they should be. 

The results from the trials this model was tested on are very telling: in the retrospective study, AI dosages were at least as effective, safe, and acceptable as intermediate physicians; in the prospective study, AI dosages obtained remarkably good scores in effectiveness, safety, acceptability, and adoption, as evaluated by bedside endocrinologists; finally, in the proof-of-concept trial, "90.2% of the AI recommendations were adopted by physicians" after 5 days of AI oversight.

While these results are extremely promising, and show that this model and technique is significantly more capable than at least junior physicians, it is still somewhat doubtful of whether it will be adopted and accepted by the general public. I think that the general fear of AI, especially in a field as delicate as healthcare, will be detrimental toward the goal of increasing clinical efficiency and relieving physician burden. With that being said, I still understand the issues brought up in that regard -- while the AI was provably better than some physicians, expert physicians still outperformed this model. If it is adopted in favor of human care, will future physicians ever be able to achieve a high level of care again? Or will future diabetics settle for sub-expert AI care?

Questions like these are interesting to investigate -- I think that before general adoption of AI into healthcare, it should -- must -- first go through countless rigorous litmus tests and prove without a shadow of doubt to be better than any doctor. Even then, I believe it should only be used sparingly.
