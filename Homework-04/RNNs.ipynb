{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObygS6qgb6Bxgxpm6KznxX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/csch7/CSCI-4170/blob/main/Homework-04/RNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the data, it seems like measurements were taken during 3 different continuous sessions, which happen to be pretty good sizes for training, validation, and test sets."
      ],
      "metadata": {
        "id": "3OFnXKvUPpkK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "R9icJg6o8wgw",
        "outputId": "b7a2fe8b-c40a-402b-8300-7176930aeb7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "# import contractions\n",
        "import re\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/YoutubeCommentsDataSet.csv\")\n",
        "\n",
        "# Used for balancing the dataset\n",
        "def load_dataset(dat, tar):\n",
        "  vals, cts = np.unique(tar, return_counts=True)\n",
        "  min_val = vals[np.argmin(cts)]\n",
        "  min_ct = min(cts)\n",
        "  new_dat = dat[tar == min_val]\n",
        "  new_tar = tar[tar == min_val]\n",
        "  for i, v in enumerate(vals):\n",
        "    if v != min_val:\n",
        "      indices = list(np.where(tar == v))[0]\n",
        "      new_ind = np.random.choice(indices, min_ct)\n",
        "      new_dat = np.append(new_dat, dat[new_ind], axis=0)\n",
        "      new_tar = np.append(new_tar, tar[new_ind])\n",
        "  return new_dat, new_tar\n",
        "\n",
        "  # Function to clean text for sentiment analysis\n",
        "def clean_text(text):\n",
        "    text = str(text).lower() # Convert to lowercase\n",
        "    # text = contractions.fix(text) # Expand contractions\n",
        "    text = re.sub(r\"http\\S+|www\\.\\S+\", \"\", text) # Remove URLs starting with http/https or www\n",
        "    text = re.sub(r\"@\\w+\", \"\", text)  # Remove mentions (@usernames) to avoid irrelevant tokens\n",
        "    text = re.sub(r\"[^a-z0-9' ]\", \"\", text) # Remove special characters\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip() # Remove extra spaces\n",
        "    return text\n",
        "\n",
        "# Apply text cleaning function to the \"Comment\" column before model training\n",
        "df[\"Cleaned_Text\"] = df[\"Comment\"].apply(clean_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.count(axis=0))\n",
        "df.dropna(axis=0, inplace = True)\n",
        "print(df.count(axis=0))\n",
        "df = df.drop_duplicates(subset = \"Comment\")"
      ],
      "metadata": {
        "id": "DRDyHtn7tDZ7",
        "outputId": "d5de9384-dbb0-4800-bf25-9ff41ed8c387",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comment         18364\n",
            "Sentiment       18408\n",
            "Cleaned_Text    18408\n",
            "dtype: int64\n",
            "Comment         18364\n",
            "Sentiment       18364\n",
            "Cleaned_Text    18364\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RIbssR4kUl1O"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ys = df['Sentiment']\n",
        "df.pop('Sentiment')"
      ],
      "metadata": {
        "id": "L9pmhrKttI7f",
        "outputId": "3f19c419-87c4-4659-b3a8-8b1fa3723ae8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         neutral\n",
              "1        negative\n",
              "2        positive\n",
              "3        negative\n",
              "4        positive\n",
              "           ...   \n",
              "18403    positive\n",
              "18404    positive\n",
              "18405     neutral\n",
              "18406    positive\n",
              "18407    positive\n",
              "Name: Sentiment, Length: 17871, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18403</th>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18404</th>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18405</th>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18406</th>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18407</th>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17871 rows Ã— 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dat = np.array(df)[:,0]\n",
        "str2id = dict()\n",
        "n_ids = 1\n",
        "max_str = 0\n",
        "for i in range(len(dat)):\n",
        "  strs = dat[i].split()\n",
        "  if len(strs) > max_str:\n",
        "    max_str = len(strs)\n",
        "  for s in strs:\n",
        "    if s not in str2id.keys():\n",
        "      str2id[s] = n_ids\n",
        "      n_ids += 1\n",
        "\n",
        "transformed_dat = np.zeros((np.shape(dat)[0], max_str), dtype = np.int32)\n",
        "for i in range(len(dat)):\n",
        "    strs = dat[i].split()\n",
        "    if len(strs) > 200:\n",
        "      continue\n",
        "    for s in range(len(strs)):\n",
        "      transformed_dat[i, s] = str2id[strs[s]]\n",
        "max_str = 200\n",
        "\n",
        "# print(transformed_y)\n",
        "\n",
        "vals, idxs, occs = np.unique(ys, return_inverse = True, return_counts = True)\n",
        "# print(vals, idxs, occs)\n",
        "\n",
        "transformed_dat, ys = load_dataset(transformed_dat, np.array(ys))\n",
        "\n",
        "transformed_y = np.zeros((np.shape(transformed_dat)[0], 3))\n",
        "transformed_y[ys == 'positive'] = [1,0,0]\n",
        "transformed_y[ys == 'neutral'] =  [0,1,0]\n",
        "transformed_y[ys == 'negative'] = [0,0,1]\n",
        "\n",
        "print(transformed_dat, transformed_y)\n",
        "\n"
      ],
      "metadata": {
        "id": "JssdUI2btkLR",
        "outputId": "55e41c59-9857-480e-f363-e37716a23587",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 46   7  47 ...   0   0   0]\n",
            " [ 89  65  90 ...   0   0   0]\n",
            " [303 304  65 ...   0   0   0]\n",
            " ...\n",
            " [174 175 867 ...   0   0   0]\n",
            " [888 284  30 ...   0   0   0]\n",
            " [888 631 311 ...   0   0   0]] [[0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " ...\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "class myRNN(nn.Module):\n",
        "  def __init__(self, input_dim, embed_dim, hidden_dim, output_dim):\n",
        "    super(myRNN, self).__init__()\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.embed = nn.Embedding(input_dim, embed_dim, padding_idx=0)\n",
        "    # self.norm = nn.LayerNorm(embed_dim)\n",
        "    self.rnn = nn.RNN(embed_dim, hidden_dim, nonlinearity='relu')\n",
        "    self.final = nn.Linear(hidden_dim, output_dim)\n",
        "    self.output = nn.Softmax(dim=1)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    batch_size = x.size()[0]\n",
        "    em = self.embed(x)\n",
        "    h0 = torch.zeros(1, batch_size, self.hidden_dim)\n",
        "    res, _ = self.rnn(em, h0)\n",
        "    final = self.final(res)[:,-1,:]\n",
        "    return self.output(final)\n",
        "\n",
        "\n",
        "\n",
        "class myLSTM(nn.Module):\n",
        "  def __init__(self, input_dim, embed_dim, hidden_dim, output_dim):\n",
        "    super().__init__()\n",
        "    self.embed = nn.Embedding(input_dim, embed_dim)\n",
        "    self.rnn = nn.LSTM(embed_dim, hidden_dim)\n",
        "    self.final = nn.Linear(hidden_dim, output_dim)\n",
        "    self.output = nn.Softmax(dim=1)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    em = self.embed(x)\n",
        "    res, _ = self.rnn(em)\n",
        "    final = self.final(res)[:,-1,:]\n",
        "    return self.output(final)\n",
        "\n",
        "\n",
        "class myGRU(nn.Module):\n",
        "\n",
        "  def __init__(self, input_dim, embed_dim, hidden_dim, output_dim):\n",
        "    super().__init__()\n",
        "    self.batch = nn.BatchNorm1d(input_dim)\n",
        "    self.embed = nn.Embedding(input_dim, embed_dim)\n",
        "    self.rnn = nn.GRU(embed_dim, hidden_dim)\n",
        "    self.final = nn.Linear(hidden_dim, output_dim)\n",
        "    self.output = nn.Softmax(dim=1)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    b = self.batch(x)\n",
        "    em = self.embed(b)\n",
        "    res, _ = self.rnn(em)\n",
        "    final = self.final(res)[:,-1,:]\n",
        "    return self.output(final)\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "y0hGVhzGGg3w"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim\n",
        "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score\n",
        "\n",
        "indices = np.arange(np.shape(transformed_dat)[0])\n",
        "np.random.shuffle(indices)\n",
        "train_x = torch.tensor(transformed_dat[indices[:10]], dtype = torch.int)\n",
        "train_y = torch.tensor(transformed_y[indices[:10]], dtype = torch.float)\n",
        "val_x = torch.tensor(transformed_dat[indices[int(len(indices)*0.6):int(len(indices)*0.8)]], dtype = torch.int)\n",
        "val_y = torch.tensor(transformed_y[indices[int(len(indices)*0.6):int(len(indices)*0.8)]], dtype = torch.float)\n",
        "test_x = torch.tensor(transformed_dat[indices[int(len(indices)*0.8):]], dtype = torch.int)\n",
        "test_y = torch.tensor(transformed_y[indices[int(len(indices)*0.8):]], dtype = torch.float)\n",
        "print(train_x)\n",
        "\n",
        "epochs = 30\n",
        "batch_size = 32\n",
        "val_epoch = 1\n",
        "\n",
        "model = myRNN(n_ids, 256, 64, 3)\n",
        "loss_fn = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.01)\n",
        "\n",
        "min_loss = 2\n",
        "since_min = 0\n",
        "\n",
        "for e in range(epochs):\n",
        "  model.train()\n",
        "  for batch in range(train_x.shape[0]//batch_size):\n",
        "    pred = model(train_x[batch*batch_size:(batch+1)*batch_size])\n",
        "    print(pred)\n",
        "    loss = loss_fn(pred, train_y[batch*batch_size:(batch+1)*batch_size])\n",
        "    if(batch%10 == 0):\n",
        "      print(\"Epoch {}; training loss: {:.5f}\".format(e, loss.item()))\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
        "    optimizer.step()\n",
        "\n",
        "  if e % val_epoch == 0:\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      pred = model(val_x)\n",
        "      loss = loss_fn(pred, val_y)\n",
        "      print(\"Validation loss: {:.5f}\".format(loss.item()))\n",
        "      print(\"Validation accuracy: {:.4f}\".format(accuracy_score(np.argmax(val_y, axis=1), np.argmax(pred, axis=1))))\n",
        "      if loss.item() < min_loss:\n",
        "        min_loss = loss.item()\n",
        "        since_min = 0\n",
        "      else:\n",
        "        since_min += 1\n",
        "    if since_min >= 5:\n",
        "      break\n",
        "\n",
        "  print()\n",
        "\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  pred = model(test_x)\n",
        "  print(pred)\n",
        "  pred = np.argmax(pred, axis=1)\n",
        "  print(pred)\n",
        "  print(\"\\nTest metrics:\")\n",
        "  print(\"f1 score: {:.5f}\".format(f1_score(np.argmax(test_y, axis=1), pred, average='macro')))\n",
        "  print(\"recall score: {:.5f}\".format(recall_score(np.argmax(test_y, axis=1), pred, average='macro')))\n",
        "  print(\"precision score: {:.5f}\".format(precision_score(np.argmax(test_y, axis=1), pred, average='macro')))\n",
        "  print(\"Overall accuracy: {:.2f}%\".format(accuracy_score(np.argmax(test_y, axis=1), pred)*100))"
      ],
      "metadata": {
        "id": "l8ldG6P271e_",
        "outputId": "af646b5b-3dbd-4b5f-954f-5b01703d675f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1456,  1213,  6763,  ...,     0,     0,     0],\n",
            "        [ 7797,    69,   133,  ...,     0,     0,     0],\n",
            "        [38811,    65,  1599,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [ 3505,    69,   133,  ...,     0,     0,     0],\n",
            "        [  260,  2967,    65,  ...,     0,     0,     0],\n",
            "        [  174,  1292,   170,  ...,     0,     0,     0]], dtype=torch.int32)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected hidden size (1, 1353, 64), got [1, 1390, 64]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-365418bbd790>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m       \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation loss: {:.5f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-09a0f5d2c7a0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mh0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mfinal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mhx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"RNN_TANH\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"RNN_RELU\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0mexpected_hidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_expected_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpermutation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_hidden_size\u001b[0;34m(self, hx, expected_hidden_size, msg)\u001b[0m\n\u001b[1;32m    343\u001b[0m     ) -> None:\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_weights_have_changed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected hidden size (1, 1353, 64), got [1, 1390, 64]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim\n",
        "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score\n",
        "\n",
        "indices = np.arange(np.shape(transformed_dat)[0])\n",
        "np.random.shuffle(indices)\n",
        "train_x = torch.tensor(transformed_dat[indices[:int(len(indices)*0.1)]], dtype = torch.int)\n",
        "train_y = torch.tensor(transformed_y[indices[:int(len(indices)*0.1)]], dtype = torch.float)\n",
        "val_x = torch.tensor(transformed_dat[indices[int(len(indices)*0.6):int(len(indices)*0.8)]], dtype = torch.int)\n",
        "val_y = torch.tensor(transformed_y[indices[int(len(indices)*0.6):int(len(indices)*0.8)]], dtype = torch.float)\n",
        "test_x = torch.tensor(transformed_dat[indices[int(len(indices)*0.8):]], dtype = torch.int)\n",
        "test_y = torch.tensor(transformed_y[indices[int(len(indices)*0.8):]], dtype = torch.float)\n",
        "\n",
        "epochs = 20\n",
        "val_epoch = 2\n",
        "\n",
        "model = myLSTM(n_ids, 64, 64, 3)\n",
        "loss_fn = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
        "\n",
        "min_loss = 2\n",
        "since_min = 0\n",
        "\n",
        "for e in range(epochs):\n",
        "  model.train()\n",
        "\n",
        "  pred = model(train_x)\n",
        "  loss = loss_fn(pred, train_y)\n",
        "  print(\"Epoch {}; training loss: {:.5f}\".format(e, loss.item()))\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "  if e % val_epoch == 0:\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      pred = model(val_x)\n",
        "      loss = loss_fn(pred, val_y)\n",
        "      print(\"Validation loss: {:.5f}\".format(loss.item()))\n",
        "      if loss.item() < min_loss:\n",
        "        min_loss = loss.item()\n",
        "        since_min = 0\n",
        "      else:\n",
        "        since_min += 1\n",
        "    if since_min >= 3:\n",
        "      break\n",
        "  print()\n",
        "\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  pred = model(test_x)\n",
        "  pred = np.argmax(pred, axis=1)\n",
        "  print(\"\\nTest metrics:\")\n",
        "  print(\"f1 score: {:.5f}\".format(f1_score(np.argmax(test_y, axis=1), pred, average='macro')))\n",
        "  print(\"recall score: {:.5f}\".format(recall_score(np.argmax(test_y, axis=1), pred, average='macro')))\n",
        "  print(\"precision score: {:.5f}\".format(precision_score(np.argmax(test_y, axis=1), pred, average='macro')))\n",
        "  print(\"Overall accuracy: {:.2f}%\".format(accuracy_score(np.argmax(test_y, axis=1), pred)*100))"
      ],
      "metadata": {
        "id": "UUtS2mQZMPlV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}